{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pleasant-upset",
   "metadata": {},
   "source": [
    "# Preparing data and training our memory on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mexican-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Needed to import local package in .ipynb\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from vision.vAE import VAE\n",
    "from memory import Memory\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-reggae",
   "metadata": {},
   "source": [
    "## Loading random rollout data & preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "engaged-revolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258, 1000, 1, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load random rollout datasets\n",
    "path = os.getcwd()\n",
    "path = path[:-6] + 'data'\n",
    "state_data = np.load(path + '/rr_data_state.npz')['arr_0']\n",
    "action_data = np.load(path + '/rr_data_action.npz')['arr_0']\n",
    "state_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "played-president",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 1000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stylish-reader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cut them to have a round number\n",
    "state_data = state_data[:250]\n",
    "action_data = action_data[:250]\n",
    "len(state_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "material-wound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from /Users/floyd/Documents/Studium/Coxi6/DRL/World-Model-LunarLanderContinuous-v2-with-PPO/world_model/vision/models\n"
     ]
    }
   ],
   "source": [
    "# Load up trained VAE\n",
    "v = VAE()\n",
    "_ = v(state_data[1,1,:,:,:,:])\n",
    "v.load(os.getcwd()[:-6] + 'vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "distinguished-ukraine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 1, 64, 64, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape to feed into vae\n",
    "state_data_b = np.reshape(state_data, (1000*250,1, 64, 64, 1))\n",
    "state_data_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-annual",
   "metadata": {},
   "source": [
    "## Turn states to latent space z-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "naughty-bermuda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 1, 32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the states into z_values\n",
    "z_values = []\n",
    "for data in state_data_b:\n",
    "    z_values.append(v.gen_z(data))\n",
    "z_values = np.asarray(z_values)\n",
    "z_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-consortium",
   "metadata": {},
   "source": [
    "## Form fitting sequence input & target data for our memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "superior-corruption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 1000, 32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping back to rollout sequence format\n",
    "z = np.reshape(z_values, (250, 1000, 32))\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "detected-emission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([250, 999, 35])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the input tensor for the memory\n",
    "x = tf.concat((z[:,:-1,:], action_data[:,:-1,:]), axis=2)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "plastic-jewelry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([250, 999, 32])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the target tensor for the memory\n",
    "y = z[:,1:,:]\n",
    "y = tf.convert_to_tensor(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "blond-dominant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((999, 35), (999, 32)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nice and neat in a dataset\n",
    "ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "paperback-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the current z-values, because loading and preprocessing takes time.\n",
    "# vae160 = we use z-values generated from a vae with loss::160\n",
    "tf.data.experimental.save(ds, os.getcwd() + '/saved_data/z_vae160', compression='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "forty-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching the dataset\n",
    "# Small batches, bc we only have 250 sequences\n",
    "ds = ds.shuffle(1).batch(4).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "linear-receiver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of batches\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-vatican",
   "metadata": {},
   "source": [
    "## Training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "developmental-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, data, epochs):\n",
    "    epoch_losses = []\n",
    "    for e in range(epochs):\n",
    "        t = time.time()\n",
    "        batch_losses = []\n",
    "        data = data.shuffle(1)\n",
    "        \n",
    "        for (x, y) in data:\n",
    "            state = model.lstm.get_zero_hidden_state(x)\n",
    "            batch_losses.append(model.train_op(x, y, state))\n",
    "            \n",
    "        epoch_losses.append(np.mean(batch_losses))\n",
    "        print(f\"Epoch: {e} done - Loss: {epoch_losses[-1]} - Time: {time.time()-t}\")\n",
    "        \n",
    "    model.save(os.getcwd() + '/160model')\n",
    "        \n",
    "    return batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "following-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Memory and corresponding loss tracker\n",
    "mem = Memory()\n",
    "loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "latin-albany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 done - Loss: 1.3459980487823486 - Time: 192.0172119140625\n",
      "Epoch: 1 done - Loss: 1.3411744832992554 - Time: 192.66047596931458\n",
      "Epoch: 2 done - Loss: 1.3365046977996826 - Time: 193.72682666778564\n",
      "Epoch: 3 done - Loss: 1.3317500352859497 - Time: 191.1217441558838\n",
      "Epoch: 4 done - Loss: 1.3277541399002075 - Time: 194.53779578208923\n",
      "Epoch: 5 done - Loss: 1.323643684387207 - Time: 210.03446984291077\n",
      "Epoch: 6 done - Loss: 1.3203871250152588 - Time: 197.75387692451477\n",
      "Epoch: 7 done - Loss: 1.3172882795333862 - Time: 195.4755642414093\n",
      "Epoch: 8 done - Loss: 1.313510775566101 - Time: 196.7855122089386\n",
      "Epoch: 9 done - Loss: 1.3100488185882568 - Time: 195.58611416816711\n",
      "Epoch: 10 done - Loss: 1.3070094585418701 - Time: 195.1967670917511\n",
      "Epoch: 11 done - Loss: 1.304121971130371 - Time: 194.9245388507843\n",
      "Epoch: 12 done - Loss: 1.3003976345062256 - Time: 195.34611320495605\n",
      "Epoch: 13 done - Loss: 1.2980632781982422 - Time: 195.06553602218628\n",
      "Epoch: 14 done - Loss: 1.295081615447998 - Time: 195.23678994178772\n",
      "Epoch: 15 done - Loss: 1.29262113571167 - Time: 227.44221210479736\n",
      "Epoch: 16 done - Loss: 1.2903616428375244 - Time: 288.81775164604187\n",
      "Epoch: 17 done - Loss: 1.2876498699188232 - Time: 278.3180899620056\n",
      "Epoch: 18 done - Loss: 1.2858738899230957 - Time: 293.25191617012024\n",
      "Epoch: 19 done - Loss: 1.2837839126586914 - Time: 327.7634379863739\n",
      "Epoch: 20 done - Loss: 1.2819932699203491 - Time: 337.8846490383148\n",
      "Epoch: 21 done - Loss: 1.2805297374725342 - Time: 253.48514318466187\n",
      "Epoch: 22 done - Loss: 1.278869867324829 - Time: 252.19384002685547\n",
      "Epoch: 23 done - Loss: 1.277247428894043 - Time: 249.99228382110596\n",
      "Epoch: 24 done - Loss: 1.2757809162139893 - Time: 249.36062383651733\n",
      "Epoch: 25 done - Loss: 1.2744693756103516 - Time: 247.8130989074707\n",
      "Epoch: 26 done - Loss: 1.2737810611724854 - Time: 252.15455889701843\n",
      "Epoch: 27 done - Loss: 1.2720340490341187 - Time: 256.9091227054596\n",
      "Epoch: 28 done - Loss: 1.2708680629730225 - Time: 275.96267008781433\n",
      "Epoch: 29 done - Loss: 1.270132303237915 - Time: 190.36534786224365\n",
      "Epoch: 30 done - Loss: 1.2691452503204346 - Time: 189.95354390144348\n",
      "Epoch: 31 done - Loss: 1.2684121131896973 - Time: 191.04084300994873\n",
      "Epoch: 32 done - Loss: 1.2678899765014648 - Time: 190.55517101287842\n",
      "Epoch: 33 done - Loss: 1.2668490409851074 - Time: 193.13756489753723\n",
      "Epoch: 34 done - Loss: 1.266064167022705 - Time: 208.0870590209961\n",
      "Epoch: 35 done - Loss: 1.2660133838653564 - Time: 199.35178184509277\n",
      "Epoch: 36 done - Loss: 1.26450514793396 - Time: 194.43662786483765\n",
      "Epoch: 37 done - Loss: 1.2641361951828003 - Time: 193.86510515213013\n",
      "Epoch: 38 done - Loss: 1.2633858919143677 - Time: 203.8467161655426\n",
      "Epoch: 39 done - Loss: 1.263636827468872 - Time: 339.08988785743713\n",
      "Epoch: 40 done - Loss: 1.26316499710083 - Time: 407.9987368583679\n",
      "Epoch: 41 done - Loss: 1.2618951797485352 - Time: 233.35897517204285\n",
      "saving model to /Users/floyd/Documents/Studium/Coxi6/DRL/World-Model-LunarLanderContinuous-v2-with-PPO/world_model/memory/160model/models\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "loss.append(train(mem, ds, 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "floating-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdrnn.Memory as PiasMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "threatened-commission",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Memory' object has no attribute 'mdn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-5440a3086857>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPiasMemory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mploss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Studium/Coxi6/DRL/World-Model-LunarLanderContinuous-v2-with-PPO/world_model/memory/mdrnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dim, latent_dim, num_timesteps, batch_size, lstm_nodes, num_mixtures, grad_clip, initial_learning_rate, end_learning_rate, epochs, batch_per_epoch, load_model, results_dir)\u001b[0m\n\u001b[1;32m    137\u001b[0m         self.models = {\n\u001b[1;32m    138\u001b[0m             \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;34m'gaussian-mix'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmdn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         }\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# use saved weights for models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Memory' object has no attribute 'mdn'"
     ]
    }
   ],
   "source": [
    "pmem = PiasMemory()\n",
    "ploss = train(pmem, ds, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-ethics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
